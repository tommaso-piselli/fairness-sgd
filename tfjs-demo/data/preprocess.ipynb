{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "\n",
    "## sys\n",
    "import random\n",
    "import time\n",
    "from glob import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "## numeric\n",
    "import numpy as np\n",
    "# import torch\n",
    "# from torch import nn, optim\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "## vis\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import collections  as mc\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "\n",
    "## notebook\n",
    "from IPython import display\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-colorblind')\n",
    "\n",
    "\n",
    "\n",
    "def dict2tensor(d, fill=None):\n",
    "    n = len(d.keys())\n",
    "    k2i = {k:i for i,k in enumerate(natsorted(d.keys()))}\n",
    "    res = np.zeros([len(d.keys()), len(d.keys())])\n",
    "    for src_node, dst_nodes in d.items():\n",
    "        for dst_node, distance in dst_nodes.items():\n",
    "            if fill is not None:\n",
    "                res[k2i[src_node],k2i[dst_node]] = fill\n",
    "            else:\n",
    "                res[k2i[src_node],k2i[dst_node]] = distance\n",
    "    return res, k2i\n",
    "\n",
    "\n",
    "def graph2json(graph, D, W, initPositions):\n",
    "    res = {k:v for k,v in graph.items()}\n",
    "    res['nodes'] = [\n",
    "        {\n",
    "            'index':i, \n",
    "            'id': node['id'],\n",
    "            'x': initPositions[i]['x'],\n",
    "            'y': initPositions[i]['y'],\n",
    "        } \n",
    "        for i, node in enumerate(graph['nodes'])]\n",
    "    res['weight'] = W.tolist()\n",
    "    res['graphDistance'] = D.tolist()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess graph for contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contest-0/automatic-1.txt',\n",
       " 'contest-0/automatic-2.txt',\n",
       " 'contest-0/automatic-3.txt',\n",
       " 'contest-0/automatic-4.txt',\n",
       " 'contest-0/automatic-5.txt',\n",
       " 'contest-0/automatic-6.txt',\n",
       " 'contest-0/automatic-7.txt',\n",
       " 'contest-0/automatic-8.txt',\n",
       " 'contest-0/automatic-9.txt',\n",
       " 'contest-0/automatic-10.txt',\n",
       " 'contest-0/automatic-12.txt',\n",
       " 'contest-0/automatic-13.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns = natsorted(\n",
    "#     glob('contest-prep-0/*.json')\n",
    "#     + glob('contest-prep-0/*.txt')\n",
    "    glob('contest-0/*.json')\n",
    "    + glob('contest-0/*.txt')\n",
    ")\n",
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in: contest-0/automatic-1.txt\n",
      "out: contest-1/automatic-1.json\n",
      "\n",
      "----------------------------------------\n",
      " in: contest-0/automatic-2.txt\n",
      "out: contest-1/automatic-2.json\n",
      "\n",
      "----------------------------------------\n",
      " in: contest-0/automatic-3.txt\n",
      "out: contest-1/automatic-3.json\n",
      "\n",
      "----------------------------------------\n",
      " in: contest-0/automatic-4.txt\n",
      "out: contest-1/automatic-4.json\n",
      "\n",
      "----------------------------------------\n",
      " in: contest-0/automatic-5.txt\n",
      "out: contest-1/automatic-5.json\n",
      "\n",
      "----------------------------------------\n",
      " in: contest-0/automatic-6.txt\n",
      "out: contest-1/automatic-6.json\n",
      "\n",
      "----------------------------------------\n",
      " in: contest-0/automatic-7.txt\n",
      "out: contest-1/automatic-7.json\n",
      "\n",
      "----------------------------------------\n",
      " in: contest-0/automatic-8.txt\n",
      "out: contest-1/automatic-8.json\n",
      "\n",
      "----------------------------------------\n",
      " in: contest-0/automatic-9.txt\n",
      "out: contest-1/automatic-9.json\n",
      "\n",
      "----------------------------------------\n",
      " in: contest-0/automatic-10.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-0431f718795f>:18: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  W = 1/(D**2+np.eye(nodeCount))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: contest-1/automatic-10.json\n",
      "\n",
      "----------------------------------------\n",
      " in: contest-0/automatic-12.txt\n",
      "out: contest-1/automatic-12.json\n",
      "\n",
      "----------------------------------------\n",
      " in: contest-0/automatic-13.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0431f718795f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnodeCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_pairs_shortest_path_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mAdj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/networkx/algorithms/shortest_paths/unweighted.py\u001b[0m in \u001b[0;36mall_pairs_shortest_path_length\u001b[0;34m(G, cutoff)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# TODO This can be trivially parallelized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/networkx/algorithms/shortest_paths/unweighted.py\u001b[0m in \u001b[0;36msingle_source_shortest_path_length\u001b[0;34m(G, source, cutoff)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mnextlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_single_shortest_path_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/networkx/algorithms/shortest_paths/unweighted.py\u001b[0m in \u001b[0;36m_single_shortest_path_length\u001b[0;34m(adj, firstlevel, cutoff)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mnextlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirstlevel\u001b[0m     \u001b[0;31m# dict of nodes to check at next level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mnextlevel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcutoff\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mthislevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnextlevel\u001b[0m  \u001b[0;31m# advance to next level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mnextlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m         \u001b[0;31m# and start a new list (fringe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fn in fns:\n",
    "    print(' in: ' + fn)\n",
    "    with open(fn) as f:\n",
    "        graph = json.load(f)\n",
    "    graph['nodes'] = natsorted(graph['nodes'], key=lambda x:x['id'])\n",
    "    \n",
    "    nodes = [n['id'] for n in graph['nodes']]\n",
    "    edges = [[e['source'], e['target']] for e in graph['edges']]\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    nodeCount = len(G.nodes)\n",
    "    D, k2i = dict2tensor(dict(nx.all_pairs_shortest_path_length(G)))\n",
    "    Adj,_ = dict2tensor(dict(G.adjacency()), fill=1)\n",
    "    \n",
    "    W = 1/(D**2+np.eye(nodeCount))\n",
    "    js = graph2json(graph, D, W, graph['nodes'])\n",
    "    \n",
    "    fnout = fn.replace('-0', '-1').replace('txt', 'json')\n",
    "    print(f'out: {fnout}')\n",
    "    if not Path(Path(fnout).parent).exists():\n",
    "        os.makedirs(Path(fnout).parent)\n",
    "    with open(fnout, 'w') as f:\n",
    "        json.dump(js, f, indent=2)\n",
    "        print()\n",
    "    print('-'*40)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## html to be used in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fn in fns:\n",
    "#     graph_name = Path(fn).name.split('.')[0]\n",
    "#     print(f\"<option value='{graph_name}'>{graph_name}</option>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fns = natsorted(\n",
    "#     glob('_tsne_output/*.json')\n",
    "#     +glob('_neato_sfdp_layouts0/*.dot'),\n",
    "#     key=lambda x:x.split('/')[-1]\n",
    "# )\n",
    "# fns = [fn for fn in fns if 'grid' in fn and 'tnse']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# for fn in fns:\n",
    "#     print(' in: ' + fn)\n",
    "#     with open(fn) as f:\n",
    "#         graph = json.load(f)\n",
    "#     print(graph['nodes'])\n",
    "#     for n in graph['nodes']:\n",
    "#         n['id'] = str(n['id'])\n",
    "        \n",
    "#     for e in graph['edges']:\n",
    "#         e['source'] = str(e['source'])\n",
    "#         e['target'] = str(e['target'])\n",
    "        \n",
    "#     for p in graph['initPositions']:\n",
    "#         p['id'] = str(p['id'])\n",
    "    \n",
    "#     for d, pos in zip(graph['nodes'], graph['initPositions']):\n",
    "#         assert d['id'] == pos['id'], f\"{d['id']} != {pos['id']}\"\n",
    "#         d['x'] = pos['x']\n",
    "#         d['y'] = pos['y']\n",
    "    \n",
    "#     graph['nodes'] = natsorted(graph['nodes'], key=lambda x:x['id'])\n",
    "    \n",
    "#     for n in graph['nodes']:\n",
    "#         print(n)\n",
    "#     nodes = [n['id'] for n in graph['nodes']]\n",
    "    \n",
    "#     print(nodes)\n",
    "#     edges = [[e['source'], e['target']] for e in graph['edges']]\n",
    "    \n",
    "#     G = nx.Graph()\n",
    "#     G.add_nodes_from(nodes)\n",
    "#     G.add_edges_from(edges)\n",
    "    \n",
    "#     nodeCount = len(G.nodes)\n",
    "#     D, k2i = dict2tensor(dict(nx.all_pairs_shortest_path_length(G)))\n",
    "#     Adj,_ = dict2tensor(dict(G.adjacency()), fill=1)\n",
    "    \n",
    "#     eye = torch.eye(nodeCount, device=device)\n",
    "#     W = 1/(D**2+eye)\n",
    "#     print(len(G.nodes), len(graph['nodes']))\n",
    "#     js = graph2json(G, D, W, graph['nodes'])\n",
    "#     fnout = fn.split('/')[-1].replace('.dot', '.json')\n",
    "#     if 'neato' in fnout:\n",
    "#         fnout = 'neato_layouts/' + fnout\n",
    "#     elif 'sfdp' in fnout:\n",
    "#         fnout = 'sfdp_layouts/' + fnout\n",
    "#     elif 'tsne' in fnout:\n",
    "#         fnout = 'tsne_layouts/' + fnout\n",
    "#     else:\n",
    "#         raise Exception\n",
    "        \n",
    "#     with open(fnout, 'w') as f:\n",
    "#         json.dump(js, f, indent=2)\n",
    "#         print(f'out: {fnout}')\n",
    "#         print()\n",
    "        \n",
    "        \n",
    "#     if 'neato.dot' in fn:\n",
    "#         init_neato = [[d['x'], d['y']] for d in graph['nodes']]\n",
    "#     if 'sfdp.dot' in fn:\n",
    "#         init_sfdp = [[d['x'], d['y']] for d in graph['nodes']]\n",
    "# #     if 'tsne.json' in fn:\n",
    "# #         init_tsne = [[d['x'], d['y']] for d in graph['nodes']]\n",
    "        \n",
    "#         js['initPosition_neato'] = init_neato\n",
    "#         js['initPosition_sfdp'] = init_sfdp\n",
    "# #         js['initPosition_tsne'] = init_tsne\n",
    "        \n",
    "#         fnout = '_'.join(fnout.split('/')[-1].split('_')[:-1]) + '.json'\n",
    "#         with open(fnout, 'w') as f:\n",
    "#             json.dump(js, f, indent=2)\n",
    "#             print('out: ' + fnout)\n",
    "#         print('-'*20)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nx.draw_networkx(G, pos={str(i):pos for i,pos in enumerate(init_neato)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
